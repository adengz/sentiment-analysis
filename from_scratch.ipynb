{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "\n",
    "from data import Vocabulary, get_dataloader\n",
    "from models import WordAveragingModel, AttentionWeightedWordAveragingModel, UAttention, dot_product_self_attention, MultiHeadSelfAttentionModel\n",
    "from learner import SentimentLearner\n",
    "\n",
    "torch.manual_seed(41)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EMBED_DIM = 256\n",
    "EMBED_DROPOUT = 0.25\n",
    "OPTIM_CLS = Adam\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 12.1 ms, total: 31.6 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'senti.{}.tsv'\n",
    "\n",
    "train_loader = get_dataloader(FILENAME.format('train'), vocab, batch_size=BATCH_SIZE)\n",
    "valid_loader = get_dataloader(FILENAME.format('dev'), vocab, batch_size=BATCH_SIZE)\n",
    "test_loader = get_dataloader(FILENAME.format('test'), vocab, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word averaging model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_avg = WordAveragingModel(len(vocab), embed_dim=EMBED_DIM, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=word_avg,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=2.5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 15.261s\n",
      "\tTrain Loss: 0.681 | Train Acc: 56.34%\n",
      "\tValid Loss: 0.664 | Valid Acc: 55.82%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 02\tWall time : 15.290s\n",
      "\tTrain Loss: 0.639 | Train Acc: 66.15%\n",
      "\tValid Loss: 0.606 | Valid Acc: 72.76%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 03\tWall time : 15.306s\n",
      "\tTrain Loss: 0.578 | Train Acc: 76.41%\n",
      "\tValid Loss: 0.544 | Valid Acc: 76.08%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 04\tWall time : 15.125s\n",
      "\tTrain Loss: 0.521 | Train Acc: 80.83%\n",
      "\tValid Loss: 0.498 | Valid Acc: 77.92%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 05\tWall time : 15.352s\n",
      "\tTrain Loss: 0.470 | Train Acc: 83.91%\n",
      "\tValid Loss: 0.471 | Valid Acc: 79.28%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 06\tWall time : 15.476s\n",
      "\tTrain Loss: 0.427 | Train Acc: 86.16%\n",
      "\tValid Loss: 0.450 | Valid Acc: 79.54%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 07\tWall time : 15.322s\n",
      "\tTrain Loss: 0.393 | Train Acc: 87.50%\n",
      "\tValid Loss: 0.435 | Valid Acc: 81.27%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 08\tWall time : 15.195s\n",
      "\tTrain Loss: 0.364 | Train Acc: 88.51%\n",
      "\tValid Loss: 0.426 | Valid Acc: 80.93%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 09\tWall time : 15.220s\n",
      "\tTrain Loss: 0.340 | Train Acc: 89.18%\n",
      "\tValid Loss: 0.419 | Valid Acc: 81.08%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 10\tWall time : 15.281s\n",
      "\tTrain Loss: 0.321 | Train Acc: 89.86%\n",
      "\tValid Loss: 0.418 | Valid Acc: 81.94%\n",
      "\tModel parameters saved to word_avg.pt\n",
      "Epoch : 11\tWall time : 15.133s\n",
      "\tTrain Loss: 0.303 | Train Acc: 90.35%\n",
      "\tValid Loss: 0.428 | Valid Acc: 81.81%\n",
      "\n",
      "Epoch : 12\tWall time : 15.294s\n",
      "\tTrain Loss: 0.288 | Train Acc: 90.72%\n",
      "\tValid Loss: 0.430 | Valid Acc: 80.84%\n",
      "\n",
      "Epoch : 13\tWall time : 15.269s\n",
      "\tTrain Loss: 0.275 | Train Acc: 91.05%\n",
      "\tValid Loss: 0.451 | Valid Acc: 80.99%\n",
      "\n",
      "Epoch : 14\tWall time : 15.268s\n",
      "\tTrain Loss: 0.264 | Train Acc: 91.35%\n",
      "\tValid Loss: 0.440 | Valid Acc: 81.51%\n",
      "\n",
      "Epoch : 15\tWall time : 15.626s\n",
      "\tTrain Loss: 0.252 | Train Acc: 91.69%\n",
      "\tValid Loss: 0.446 | Valid Acc: 81.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_avg_filename = 'word_avg.pt'\n",
    "learner.train(epochs=EPOCHS, filename=word_avg_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(word_avg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.404 | Test Acc: 82.66%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = learner.model.word_embedding\n",
    "norms = pd.Series(torch.linalg.norm(word_embedding, dim=1).cpu(), index=vocab.itos).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "too           5.555303\n",
       "touching      5.571635\n",
       "stupid        5.581569\n",
       "enjoyable     5.595304\n",
       "dull          5.607146\n",
       "terrific      5.646525\n",
       "remarkable    5.671368\n",
       "hilarious     5.692608\n",
       "best          5.705451\n",
       "flat          5.868037\n",
       "powerful      5.908876\n",
       "solid         5.989082\n",
       "mess          6.032230\n",
       "bad           6.716216\n",
       "worst         7.029595\n",
       "dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pad>              0.000000\n",
       "<unk>              0.017731\n",
       "play-doh           0.099339\n",
       "mikes              0.100724\n",
       "boom               0.101232\n",
       "conjured           0.101493\n",
       "liman              0.102587\n",
       "flck               0.104340\n",
       "helpful            0.105775\n",
       "happily-ever       0.106357\n",
       "schnieder          0.107072\n",
       "the                0.108152\n",
       "passages           0.109647\n",
       "naipaul            0.109693\n",
       "post-production    0.109976\n",
       "dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention weighted word averaging model\n",
    "## w/ cosine similarity attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_att = AttentionWeightedWordAveragingModel(len(vocab), embed_dim=EMBED_DIM, attention=UAttention(EMBED_DIM), embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=cos_att,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=2.5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 15.795s\n",
      "\tTrain Loss: 0.681 | Train Acc: 56.72%\n",
      "\tValid Loss: 0.662 | Valid Acc: 56.66%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 02\tWall time : 15.648s\n",
      "\tTrain Loss: 0.634 | Train Acc: 69.50%\n",
      "\tValid Loss: 0.589 | Valid Acc: 75.53%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 03\tWall time : 15.721s\n",
      "\tTrain Loss: 0.569 | Train Acc: 79.09%\n",
      "\tValid Loss: 0.535 | Valid Acc: 74.94%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 04\tWall time : 15.506s\n",
      "\tTrain Loss: 0.507 | Train Acc: 82.84%\n",
      "\tValid Loss: 0.477 | Valid Acc: 77.91%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 05\tWall time : 15.657s\n",
      "\tTrain Loss: 0.455 | Train Acc: 85.34%\n",
      "\tValid Loss: 0.458 | Valid Acc: 78.31%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 06\tWall time : 15.495s\n",
      "\tTrain Loss: 0.412 | Train Acc: 87.13%\n",
      "\tValid Loss: 0.417 | Valid Acc: 81.05%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 07\tWall time : 15.816s\n",
      "\tTrain Loss: 0.378 | Train Acc: 88.28%\n",
      "\tValid Loss: 0.418 | Valid Acc: 80.88%\n",
      "\n",
      "Epoch : 08\tWall time : 15.472s\n",
      "\tTrain Loss: 0.350 | Train Acc: 89.11%\n",
      "\tValid Loss: 0.431 | Valid Acc: 80.94%\n",
      "\n",
      "Epoch : 09\tWall time : 15.714s\n",
      "\tTrain Loss: 0.326 | Train Acc: 89.81%\n",
      "\tValid Loss: 0.416 | Valid Acc: 80.99%\n",
      "\tModel parameters saved to cos_att.pt\n",
      "Epoch : 10\tWall time : 15.697s\n",
      "\tTrain Loss: 0.306 | Train Acc: 90.35%\n",
      "\tValid Loss: 0.416 | Valid Acc: 81.90%\n",
      "\n",
      "Epoch : 11\tWall time : 15.592s\n",
      "\tTrain Loss: 0.290 | Train Acc: 90.80%\n",
      "\tValid Loss: 0.450 | Valid Acc: 79.89%\n",
      "\n",
      "Epoch : 12\tWall time : 15.647s\n",
      "\tTrain Loss: 0.275 | Train Acc: 91.24%\n",
      "\tValid Loss: 0.423 | Valid Acc: 82.23%\n",
      "\n",
      "Epoch : 13\tWall time : 15.655s\n",
      "\tTrain Loss: 0.262 | Train Acc: 91.54%\n",
      "\tValid Loss: 0.435 | Valid Acc: 81.61%\n",
      "\n",
      "Epoch : 14\tWall time : 15.630s\n",
      "\tTrain Loss: 0.250 | Train Acc: 91.86%\n",
      "\tValid Loss: 0.448 | Valid Acc: 81.57%\n",
      "\n",
      "Epoch : 15\tWall time : 15.515s\n",
      "\tTrain Loss: 0.239 | Train Acc: 92.08%\n",
      "\tValid Loss: 0.453 | Valid Acc: 81.08%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cos_att_filename = 'cos_att.pt'\n",
    "learner.train(epochs=EPOCHS, filename=cos_att_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(cos_att_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.391 | Test Acc: 83.71%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarities between vector u and word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer = learner.model.attention\n",
    "embeddings = learner.model.embedding.weight.data\n",
    "\n",
    "cosine_similarities = pd.Series(att_layer.cosine_similarity_to_u(embeddings).detach().cpu(), index=vocab.itos).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buñuel           0.909628\n",
       "irrelevancy      0.912352\n",
       "seventeen        0.912658\n",
       "batman           0.916255\n",
       "litmus           0.917946\n",
       "single-minded    0.922519\n",
       "semen            0.929406\n",
       "spider           0.936180\n",
       "substances       0.943009\n",
       "reduced          0.943857\n",
       "fluffy           0.945651\n",
       "detract          0.956421\n",
       "disappoint       0.957859\n",
       "ignorant         0.968111\n",
       "overrun          0.973900\n",
       "dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s          -0.997821\n",
       "his         -0.996826\n",
       "the         -0.996709\n",
       "abroad      -0.996542\n",
       "maintain    -0.995989\n",
       "can         -0.994987\n",
       "earnhart    -0.994704\n",
       "across      -0.994373\n",
       "attempted   -0.994143\n",
       "change      -0.993333\n",
       "feel        -0.993191\n",
       "readily     -0.993008\n",
       "-           -0.993005\n",
       "its         -0.992905\n",
       "mores       -0.992865\n",
       "dtype: float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention variance among frequent words in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "from collections import defaultdict\n",
    "\n",
    "MAX_FREQ = 100\n",
    "upper_bound = len(vocab) - bisect.bisect_right(vocab.freqs[::-1], MAX_FREQ)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_attention_stats(learner):\n",
    "    attentions = defaultdict(list)\n",
    "    \n",
    "    embedding_layer = learner.model.embedding\n",
    "    attention_layer = learner.model.attention\n",
    "    for batch in train_loader:\n",
    "        sequences, _ = batch\n",
    "        sequences = sequences.to(learner.device)\n",
    "        \n",
    "        mask = torch.where(sequences < upper_bound, sequences, 0).bool()\n",
    "        attention = attention_layer(embedding_layer(sequences))\n",
    "        masked_sequences = torch.masked_select(sequences, mask).tolist()\n",
    "        masked_attention = torch.masked_select(attention, mask).tolist()\n",
    "        for i, att in zip(masked_sequences, masked_attention):\n",
    "            attentions[i].append(att)\n",
    "        \n",
    "    return attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 84.5 ms, total: 14.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stats = get_attention_stats(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['word', 'mean', 'std'])\n",
    "for k, v in stats.items():\n",
    "    attentions = torch.Tensor(v)\n",
    "    df = df.append({'word': vocab.itos[k], 'mean': attentions.mean().item(), 'std': attentions.std().item()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barely</th>\n",
       "      <td>0.049742</td>\n",
       "      <td>0.008348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instead</th>\n",
       "      <td>0.049808</td>\n",
       "      <td>0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheap</th>\n",
       "      <td>0.048184</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>0.050206</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>less</th>\n",
       "      <td>0.050108</td>\n",
       "      <td>0.007332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clichés</th>\n",
       "      <td>0.049925</td>\n",
       "      <td>0.007235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feels</th>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.007180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neither</th>\n",
       "      <td>0.050422</td>\n",
       "      <td>0.007165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>0.050130</td>\n",
       "      <td>0.007164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impossible</th>\n",
       "      <td>0.045538</td>\n",
       "      <td>0.007145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>0.047840</td>\n",
       "      <td>0.007135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokes</th>\n",
       "      <td>0.047010</td>\n",
       "      <td>0.007050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same</th>\n",
       "      <td>0.046216</td>\n",
       "      <td>0.007047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.007010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thin</th>\n",
       "      <td>0.048321</td>\n",
       "      <td>0.007006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.006999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dumb</th>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.006964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bland</th>\n",
       "      <td>0.049066</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mess</th>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.006925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trying</th>\n",
       "      <td>0.047829</td>\n",
       "      <td>0.006923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0.046596</td>\n",
       "      <td>0.006913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nor</th>\n",
       "      <td>0.050991</td>\n",
       "      <td>0.006880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacking</th>\n",
       "      <td>0.050782</td>\n",
       "      <td>0.006842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0.048143</td>\n",
       "      <td>0.006827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lacks</th>\n",
       "      <td>0.050702</td>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down</th>\n",
       "      <td>0.046381</td>\n",
       "      <td>0.006784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>0.048204</td>\n",
       "      <td>0.006774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.006768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idea</th>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.006759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fails</th>\n",
       "      <td>0.051752</td>\n",
       "      <td>0.006737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean       std\n",
       "word                          \n",
       "barely      0.049742  0.008348\n",
       "instead     0.049808  0.008089\n",
       "cheap       0.048184  0.008065\n",
       "waste       0.050206  0.007693\n",
       "less        0.050108  0.007332\n",
       "clichés     0.049925  0.007235\n",
       "feels       0.046616  0.007180\n",
       "neither     0.050422  0.007165\n",
       "awful       0.050130  0.007164\n",
       "impossible  0.045538  0.007145\n",
       "left        0.047840  0.007135\n",
       "jokes       0.047010  0.007050\n",
       "same        0.046216  0.007047\n",
       "none        0.052300  0.007010\n",
       "thin        0.048321  0.007006\n",
       "cold        0.049050  0.006999\n",
       "dumb        0.049262  0.006964\n",
       "bland       0.049066  0.006930\n",
       "mess        0.050160  0.006925\n",
       "trying      0.047829  0.006923\n",
       "video       0.046596  0.006913\n",
       "nor         0.050991  0.006880\n",
       "lacking     0.050782  0.006842\n",
       "not         0.048143  0.006827\n",
       "lacks       0.050702  0.006794\n",
       "down        0.046381  0.006784\n",
       "were        0.048204  0.006774\n",
       "no          0.049133  0.006768\n",
       "idea        0.047625  0.006759\n",
       "fails       0.051752  0.006737"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('std', ascending=False)\n",
    "df = df.set_index('word', drop=True)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention weighted word averaging model\n",
    "## w/ dot product self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_att = AttentionWeightedWordAveragingModel(len(vocab), embed_dim=EMBED_DIM, attention=dot_product_self_attention, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=dp_att,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=5e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 15.595s\n",
      "\tTrain Loss: 0.690 | Train Acc: 55.77%\n",
      "\tValid Loss: 0.691 | Valid Acc: 50.64%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 02\tWall time : 15.748s\n",
      "\tTrain Loss: 0.684 | Train Acc: 55.90%\n",
      "\tValid Loss: 0.674 | Valid Acc: 51.80%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 03\tWall time : 15.556s\n",
      "\tTrain Loss: 0.659 | Train Acc: 60.23%\n",
      "\tValid Loss: 0.627 | Valid Acc: 66.14%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 04\tWall time : 15.628s\n",
      "\tTrain Loss: 0.615 | Train Acc: 67.93%\n",
      "\tValid Loss: 0.567 | Valid Acc: 72.80%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 05\tWall time : 15.665s\n",
      "\tTrain Loss: 0.575 | Train Acc: 71.70%\n",
      "\tValid Loss: 0.543 | Valid Acc: 73.74%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 06\tWall time : 15.546s\n",
      "\tTrain Loss: 0.544 | Train Acc: 73.85%\n",
      "\tValid Loss: 0.537 | Valid Acc: 74.28%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 07\tWall time : 15.673s\n",
      "\tTrain Loss: 0.516 | Train Acc: 75.88%\n",
      "\tValid Loss: 0.507 | Valid Acc: 75.38%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 08\tWall time : 15.848s\n",
      "\tTrain Loss: 0.491 | Train Acc: 77.48%\n",
      "\tValid Loss: 0.509 | Valid Acc: 76.41%\n",
      "\n",
      "Epoch : 09\tWall time : 15.640s\n",
      "\tTrain Loss: 0.468 | Train Acc: 78.78%\n",
      "\tValid Loss: 0.504 | Valid Acc: 76.37%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 10\tWall time : 15.689s\n",
      "\tTrain Loss: 0.449 | Train Acc: 79.82%\n",
      "\tValid Loss: 0.496 | Valid Acc: 76.80%\n",
      "\tModel parameters saved to dp_att.pt\n",
      "Epoch : 11\tWall time : 15.573s\n",
      "\tTrain Loss: 0.431 | Train Acc: 80.94%\n",
      "\tValid Loss: 0.506 | Valid Acc: 76.62%\n",
      "\n",
      "Epoch : 12\tWall time : 15.672s\n",
      "\tTrain Loss: 0.416 | Train Acc: 81.77%\n",
      "\tValid Loss: 0.520 | Valid Acc: 76.14%\n",
      "\n",
      "Epoch : 13\tWall time : 15.777s\n",
      "\tTrain Loss: 0.402 | Train Acc: 82.61%\n",
      "\tValid Loss: 0.519 | Valid Acc: 76.96%\n",
      "\n",
      "Epoch : 14\tWall time : 15.583s\n",
      "\tTrain Loss: 0.389 | Train Acc: 83.28%\n",
      "\tValid Loss: 0.511 | Valid Acc: 77.81%\n",
      "\n",
      "Epoch : 15\tWall time : 15.608s\n",
      "\tTrain Loss: 0.376 | Train Acc: 84.01%\n",
      "\tValid Loss: 0.528 | Valid Acc: 77.34%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp_att_filename = 'dp_att.pt'\n",
    "learner.train(epochs=EPOCHS, filename=dp_att_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(dp_att_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.490 | Test Acc: 77.97%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention weighted word averaging model\n",
    "## w/ dot product self-attention\n",
    "## adding residual connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_att_rc = AttentionWeightedWordAveragingModel(len(vocab), embed_dim=EMBED_DIM, attention=dot_product_self_attention, res_conn=True, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=dp_att_rc,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=5e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 15.544s\n",
      "\tTrain Loss: 0.691 | Train Acc: 55.74%\n",
      "\tValid Loss: 0.687 | Valid Acc: 51.88%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 02\tWall time : 15.694s\n",
      "\tTrain Loss: 0.683 | Train Acc: 57.73%\n",
      "\tValid Loss: 0.674 | Valid Acc: 53.25%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 03\tWall time : 15.608s\n",
      "\tTrain Loss: 0.660 | Train Acc: 63.53%\n",
      "\tValid Loss: 0.629 | Valid Acc: 66.52%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 04\tWall time : 15.586s\n",
      "\tTrain Loss: 0.619 | Train Acc: 70.72%\n",
      "\tValid Loss: 0.577 | Valid Acc: 73.97%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 05\tWall time : 15.907s\n",
      "\tTrain Loss: 0.576 | Train Acc: 74.61%\n",
      "\tValid Loss: 0.542 | Valid Acc: 74.71%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 06\tWall time : 15.737s\n",
      "\tTrain Loss: 0.540 | Train Acc: 76.72%\n",
      "\tValid Loss: 0.514 | Valid Acc: 75.92%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 07\tWall time : 15.653s\n",
      "\tTrain Loss: 0.510 | Train Acc: 78.43%\n",
      "\tValid Loss: 0.511 | Valid Acc: 75.68%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 08\tWall time : 15.671s\n",
      "\tTrain Loss: 0.483 | Train Acc: 79.86%\n",
      "\tValid Loss: 0.498 | Valid Acc: 77.04%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 09\tWall time : 15.676s\n",
      "\tTrain Loss: 0.459 | Train Acc: 81.11%\n",
      "\tValid Loss: 0.497 | Valid Acc: 77.67%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 10\tWall time : 15.612s\n",
      "\tTrain Loss: 0.439 | Train Acc: 82.23%\n",
      "\tValid Loss: 0.497 | Valid Acc: 77.49%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 11\tWall time : 15.663s\n",
      "\tTrain Loss: 0.421 | Train Acc: 83.22%\n",
      "\tValid Loss: 0.493 | Valid Acc: 78.12%\n",
      "\tModel parameters saved to dp_att_rc.pt\n",
      "Epoch : 12\tWall time : 15.609s\n",
      "\tTrain Loss: 0.404 | Train Acc: 83.95%\n",
      "\tValid Loss: 0.507 | Valid Acc: 77.92%\n",
      "\n",
      "Epoch : 13\tWall time : 15.716s\n",
      "\tTrain Loss: 0.389 | Train Acc: 84.73%\n",
      "\tValid Loss: 0.499 | Valid Acc: 78.64%\n",
      "\n",
      "Epoch : 14\tWall time : 15.738s\n",
      "\tTrain Loss: 0.377 | Train Acc: 85.36%\n",
      "\tValid Loss: 0.495 | Valid Acc: 78.79%\n",
      "\n",
      "Epoch : 15\tWall time : 15.666s\n",
      "\tTrain Loss: 0.363 | Train Acc: 85.93%\n",
      "\tValid Loss: 0.486 | Valid Acc: 79.98%\n",
      "\tModel parameters saved to dp_att_rc.pt\n"
     ]
    }
   ],
   "source": [
    "dp_att_rc_filename = 'dp_att_rc.pt'\n",
    "learner.train(epochs=EPOCHS, filename=dp_att_rc_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(dp_att_rc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.445 | Test Acc: 81.37%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer style attention model\n",
    "## w/ single attention head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_head = MultiHeadSelfAttentionModel(len(vocab), model_dim=EMBED_DIM, num_heads=1, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=single_head,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 17.272s\n",
      "\tTrain Loss: 0.704 | Train Acc: 48.00%\n",
      "\tValid Loss: 0.689 | Valid Acc: 50.07%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 02\tWall time : 17.317s\n",
      "\tTrain Loss: 0.679 | Train Acc: 55.84%\n",
      "\tValid Loss: 0.678 | Valid Acc: 51.35%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 03\tWall time : 17.184s\n",
      "\tTrain Loss: 0.659 | Train Acc: 57.69%\n",
      "\tValid Loss: 0.644 | Valid Acc: 60.46%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 04\tWall time : 17.317s\n",
      "\tTrain Loss: 0.619 | Train Acc: 67.02%\n",
      "\tValid Loss: 0.591 | Valid Acc: 73.74%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 05\tWall time : 17.178s\n",
      "\tTrain Loss: 0.565 | Train Acc: 74.97%\n",
      "\tValid Loss: 0.537 | Valid Acc: 77.32%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 06\tWall time : 17.166s\n",
      "\tTrain Loss: 0.508 | Train Acc: 79.69%\n",
      "\tValid Loss: 0.493 | Valid Acc: 77.14%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 07\tWall time : 17.062s\n",
      "\tTrain Loss: 0.454 | Train Acc: 83.10%\n",
      "\tValid Loss: 0.452 | Valid Acc: 79.21%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 08\tWall time : 17.134s\n",
      "\tTrain Loss: 0.407 | Train Acc: 85.60%\n",
      "\tValid Loss: 0.439 | Valid Acc: 81.02%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 09\tWall time : 17.167s\n",
      "\tTrain Loss: 0.367 | Train Acc: 87.45%\n",
      "\tValid Loss: 0.441 | Valid Acc: 80.66%\n",
      "\n",
      "Epoch : 10\tWall time : 17.163s\n",
      "\tTrain Loss: 0.333 | Train Acc: 88.65%\n",
      "\tValid Loss: 0.412 | Valid Acc: 82.77%\n",
      "\tModel parameters saved to single_head.pt\n",
      "Epoch : 11\tWall time : 17.276s\n",
      "\tTrain Loss: 0.307 | Train Acc: 89.42%\n",
      "\tValid Loss: 0.442 | Valid Acc: 81.05%\n",
      "\n",
      "Epoch : 12\tWall time : 17.297s\n",
      "\tTrain Loss: 0.285 | Train Acc: 90.08%\n",
      "\tValid Loss: 0.444 | Valid Acc: 81.10%\n",
      "\n",
      "Epoch : 13\tWall time : 17.310s\n",
      "\tTrain Loss: 0.267 | Train Acc: 90.51%\n",
      "\tValid Loss: 0.437 | Valid Acc: 81.24%\n",
      "\n",
      "Epoch : 14\tWall time : 17.330s\n",
      "\tTrain Loss: 0.250 | Train Acc: 91.03%\n",
      "\tValid Loss: 0.466 | Valid Acc: 81.05%\n",
      "\n",
      "Epoch : 15\tWall time : 17.221s\n",
      "\tTrain Loss: 0.238 | Train Acc: 91.41%\n",
      "\tValid Loss: 0.478 | Valid Acc: 81.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_head_filename = 'single_head.pt'\n",
    "learner.train(epochs=EPOCHS, filename=single_head_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(single_head_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.415 | Test Acc: 81.46%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer style attention model\n",
    "## w/ single attention head & positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_head_pe = MultiHeadSelfAttentionModel(len(vocab), model_dim=EMBED_DIM, num_heads=1, pos_encode=True, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=single_head_pe,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 17.306s\n",
      "\tTrain Loss: 0.690 | Train Acc: 54.63%\n",
      "\tValid Loss: 0.696 | Valid Acc: 50.64%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 02\tWall time : 17.248s\n",
      "\tTrain Loss: 0.687 | Train Acc: 55.83%\n",
      "\tValid Loss: 0.704 | Valid Acc: 50.07%\n",
      "\n",
      "Epoch : 03\tWall time : 17.111s\n",
      "\tTrain Loss: 0.686 | Train Acc: 55.85%\n",
      "\tValid Loss: 0.700 | Valid Acc: 51.21%\n",
      "\n",
      "Epoch : 04\tWall time : 17.322s\n",
      "\tTrain Loss: 0.686 | Train Acc: 55.80%\n",
      "\tValid Loss: 0.699 | Valid Acc: 49.78%\n",
      "\n",
      "Epoch : 05\tWall time : 17.249s\n",
      "\tTrain Loss: 0.686 | Train Acc: 55.79%\n",
      "\tValid Loss: 0.696 | Valid Acc: 51.07%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 06\tWall time : 17.136s\n",
      "\tTrain Loss: 0.685 | Train Acc: 55.77%\n",
      "\tValid Loss: 0.697 | Valid Acc: 50.92%\n",
      "\n",
      "Epoch : 07\tWall time : 17.169s\n",
      "\tTrain Loss: 0.685 | Train Acc: 55.71%\n",
      "\tValid Loss: 0.696 | Valid Acc: 51.49%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 08\tWall time : 17.048s\n",
      "\tTrain Loss: 0.684 | Train Acc: 55.81%\n",
      "\tValid Loss: 0.695 | Valid Acc: 50.92%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 09\tWall time : 17.205s\n",
      "\tTrain Loss: 0.682 | Train Acc: 55.94%\n",
      "\tValid Loss: 0.688 | Valid Acc: 51.07%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 10\tWall time : 17.323s\n",
      "\tTrain Loss: 0.677 | Train Acc: 56.16%\n",
      "\tValid Loss: 0.685 | Valid Acc: 49.92%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 11\tWall time : 17.262s\n",
      "\tTrain Loss: 0.664 | Train Acc: 59.54%\n",
      "\tValid Loss: 0.662 | Valid Acc: 58.42%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 12\tWall time : 17.406s\n",
      "\tTrain Loss: 0.637 | Train Acc: 64.52%\n",
      "\tValid Loss: 0.636 | Valid Acc: 61.89%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 13\tWall time : 17.313s\n",
      "\tTrain Loss: 0.595 | Train Acc: 68.46%\n",
      "\tValid Loss: 0.615 | Valid Acc: 64.17%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 14\tWall time : 17.292s\n",
      "\tTrain Loss: 0.561 | Train Acc: 71.50%\n",
      "\tValid Loss: 0.599 | Valid Acc: 67.04%\n",
      "\tModel parameters saved to single_head_pe.pt\n",
      "Epoch : 15\tWall time : 17.155s\n",
      "\tTrain Loss: 0.534 | Train Acc: 73.82%\n",
      "\tValid Loss: 0.587 | Valid Acc: 68.47%\n",
      "\tModel parameters saved to single_head_pe.pt\n"
     ]
    }
   ],
   "source": [
    "single_head_pe_filename = 'single_head_pe.pt'\n",
    "learner.train(epochs=EPOCHS, filename=single_head_pe_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(single_head_pe_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.624 | Test Acc: 66.83%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer style attention model\n",
    "## w/ multiple attention heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head = MultiHeadSelfAttentionModel(len(vocab), model_dim=EMBED_DIM, num_heads=4, embed_dropout=EMBED_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SentimentLearner(\n",
    "    model=multi_head,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_cls=OPTIM_CLS,\n",
    "    lr=5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01\tWall time : 17.186s\n",
      "\tTrain Loss: 0.779 | Train Acc: 44.18%\n",
      "\tValid Loss: 0.704 | Valid Acc: 48.93%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 02\tWall time : 17.107s\n",
      "\tTrain Loss: 0.700 | Train Acc: 48.29%\n",
      "\tValid Loss: 0.680 | Valid Acc: 57.91%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 03\tWall time : 17.198s\n",
      "\tTrain Loss: 0.670 | Train Acc: 60.78%\n",
      "\tValid Loss: 0.659 | Valid Acc: 54.55%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 04\tWall time : 17.185s\n",
      "\tTrain Loss: 0.639 | Train Acc: 64.80%\n",
      "\tValid Loss: 0.621 | Valid Acc: 64.51%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 05\tWall time : 17.163s\n",
      "\tTrain Loss: 0.590 | Train Acc: 75.80%\n",
      "\tValid Loss: 0.562 | Valid Acc: 76.14%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 06\tWall time : 17.064s\n",
      "\tTrain Loss: 0.537 | Train Acc: 80.22%\n",
      "\tValid Loss: 0.515 | Valid Acc: 77.22%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 07\tWall time : 17.066s\n",
      "\tTrain Loss: 0.488 | Train Acc: 82.88%\n",
      "\tValid Loss: 0.491 | Valid Acc: 78.45%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 08\tWall time : 17.203s\n",
      "\tTrain Loss: 0.445 | Train Acc: 85.13%\n",
      "\tValid Loss: 0.465 | Valid Acc: 79.00%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 09\tWall time : 17.189s\n",
      "\tTrain Loss: 0.409 | Train Acc: 86.71%\n",
      "\tValid Loss: 0.440 | Valid Acc: 80.45%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 10\tWall time : 17.268s\n",
      "\tTrain Loss: 0.379 | Train Acc: 88.09%\n",
      "\tValid Loss: 0.435 | Valid Acc: 81.38%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 11\tWall time : 17.287s\n",
      "\tTrain Loss: 0.354 | Train Acc: 89.03%\n",
      "\tValid Loss: 0.437 | Valid Acc: 80.81%\n",
      "\n",
      "Epoch : 12\tWall time : 17.345s\n",
      "\tTrain Loss: 0.331 | Train Acc: 89.79%\n",
      "\tValid Loss: 0.420 | Valid Acc: 81.03%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 13\tWall time : 17.301s\n",
      "\tTrain Loss: 0.312 | Train Acc: 90.32%\n",
      "\tValid Loss: 0.419 | Valid Acc: 82.10%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 14\tWall time : 17.346s\n",
      "\tTrain Loss: 0.295 | Train Acc: 90.79%\n",
      "\tValid Loss: 0.411 | Valid Acc: 81.32%\n",
      "\tModel parameters saved to multi_head.pt\n",
      "Epoch : 15\tWall time : 17.121s\n",
      "\tTrain Loss: 0.280 | Train Acc: 91.19%\n",
      "\tValid Loss: 0.432 | Valid Acc: 81.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_head_filename = 'multi_head.pt'\n",
    "learner.train(epochs=EPOCHS, filename=multi_head_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model_params(multi_head_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.395 | Test Acc: 83.52%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = learner.evaluate(test_loader)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
